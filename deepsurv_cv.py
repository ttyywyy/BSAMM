#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ğŸ’¡ DeepSurvï¼ˆPyTorch ç‰ˆï¼‰+ 5å€äº¤å‰éªŒè¯
--------------------------------
â€¢ ç”¨å…¨è¿æ¥ MLP æ›¿æ¢ Cox å›å½’çš„çº¿æ€§é¡¹
â€¢ æŸå¤±ä»æ˜¯è´Ÿå¯¹æ•°éƒ¨åˆ†ä¼¼ç„¶ (Cox PH loss)
â€¢ è¯„ä»·æŒ‡æ ‡ä½¿ç”¨ concordance index (C-index)
â€¢ æ–°å¢ï¼š5å€äº¤å‰éªŒè¯åŠŸèƒ½
"""

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0. ä¾èµ–åŒ… â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
import torch
from torch import nn
from torch.utils.data import Dataset, DataLoader, Subset
import pandas as pd
import numpy as np
from lifelines.utils import concordance_index
from sklearn.model_selection import KFold
import matplotlib.pyplot as plt
import seaborn as sns
import os
from typing import List, Tuple, Dict
import warnings

warnings.filterwarnings('ignore')

# è®¾ç½®ä¸­æ–‡å­—ä½“
plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1. å…¨å±€è¶…å‚æ•° (ä¸€å¤„ä¿®æ”¹ï¼Œå…¨å±€ç”Ÿæ•ˆ) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
CONFIG = dict(
    HIDDEN_SIZES=(128, 64),  # MLP ç»“æ„
    DROPOUT=0.4,
    LR=1e-4,
    WEIGHT_DECAY=1e-5,
    EPOCHS=100,  # å‡å°‘epochsä»¥é€‚åº”äº¤å‰éªŒè¯
    BATCH_SIZE=64,
    TRAIN_RATIO=0.9,  # åœ¨äº¤å‰éªŒè¯ä¸­ï¼Œè¿™ä¸ªå‚æ•°ç”¨äºè®­ç»ƒé›†å†…éƒ¨çš„éªŒè¯
    DEVICE="cuda" if torch.cuda.is_available() else "cpu",
    SEED=42,
    # äº¤å‰éªŒè¯å‚æ•°
    CV_FOLDS=10,  # 5å€äº¤å‰éªŒè¯
    PATIENCE=50,  # æ—©åœè€å¿ƒ
    MIN_DELTA=0.001,  # æœ€å°æ”¹å–„é˜ˆå€¼
)

1
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 2. æ•°å€¼ç¨³å®šçš„ Cox-PH æŸå¤± â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def cox_ph_loss(risk_score: torch.Tensor,
                time: torch.Tensor,
                event: torch.Tensor,
                eps: float = 1e-8) -> torch.Tensor:
    """
    risk_score : (N,) ç½‘ç»œè¾“å‡ºçš„å¯¹æ•°é£é™©
    time       : (N,) ç”Ÿå­˜ / éšè®¿æ—¶é—´
    event      : (N,) 1=äº‹ä»¶ï¼Œ0=åˆ å¤±
    """
    # ç»Ÿä¸€å±•å¹³
    risk = risk_score.view(-1)
    time = time.view(-1)
    event = event.view(-1)

    # â‘  å…ˆæŒ‰æ—¶é—´é™åºæ’åˆ—  (Risk set = t_j >= t_i)
    order = torch.argsort(time, descending=True)
    risk, event = risk[order], event[order]

    # â‘¡ log ç´¯åŠ æ±‚å’Œï¼šlog Î£_{jâ‰¥i} e^{risk_j}
    log_cumsum = torch.logcumsumexp(risk, dim=0)

    # â‘¢ è´Ÿå¯¹æ•°ä¼¼ç„¶ (åªå¯¹äº‹ä»¶æ ·æœ¬æ±‚å’Œ)
    nll = -(event * (risk - log_cumsum)).sum()

    # â‘£ ç”¨äº‹ä»¶æ•°å½’ä¸€åŒ–ï¼Œé˜²æ­¢å…¨åˆ å¤±æ—¶ /0
    return nll / (event.sum() + eps)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 3. DeepSurv ç½‘ç»œ (MLP) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
class DeepSurvMLP(nn.Module):
    def __init__(self, num_features: int):
        super().__init__()

        sizes = CONFIG["HIDDEN_SIZES"]
        dropout = CONFIG["DROPOUT"]

        layers, in_dim = [], num_features
        for h in sizes:
            layers += [nn.Linear(in_dim, h),
                       nn.ReLU(),
                       nn.Dropout(dropout)]
            in_dim = h
        layers += [nn.Linear(in_dim, 1)]  # è¾“å‡º 1 ä¸ªé£é™©åˆ†æ•°

        self.mlp = nn.Sequential(*layers)
        self.apply(self._init_weights)

    @staticmethod
    def _init_weights(m):
        if isinstance(m, nn.Linear):
            nn.init.xavier_uniform_(m.weight)
            nn.init.zeros_(m.bias)

    def forward(self, x):
        return self.mlp(x).squeeze(-1)  # shape -> (B,)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 4. è¯»å– CSV çš„ Dataset â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
class SurvivalDataset(Dataset):
    """
    æœŸæœ›ï¼š
      â€¢ X.csv  è¡Œ=æ ·æœ¬ï¼Œåˆ—=æ•°å€¼ç‰¹å¾ï¼ˆå·²åš one-hot / æ ‡å‡†åŒ–ï¼‰
      â€¢ y.csv  åˆ— = [id, time, event]
    """

    def __init__(self, x_path: str, y_path: str):
        self.x = torch.tensor(pd.read_csv(x_path, index_col=0).values,
                              dtype=torch.float32)
        ydf = pd.read_csv(y_path, index_col=0)
        self.time = torch.tensor(ydf["time"].values, dtype=torch.float32)
        self.event = torch.tensor(ydf["event"].values, dtype=torch.float32)

    def __len__(self): return len(self.x)

    def __getitem__(self, idx):
        return self.x[idx], self.time[idx], self.event[idx]


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 5. æ—©åœæœºåˆ¶ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# class EarlyStopping:
#     """æ—©åœæœºåˆ¶"""
#
#     def __init__(self, patience=50, min_delta=0.001):
#         self.patience = patience
#         self.min_delta = min_delta
#         self.counter = 0
#         self.best_score = None
#
#     def __call__(self, val_score):
#         if self.best_score is None:
#             self.best_score = val_score
#         elif val_score < self.best_score + self.min_delta:
#             self.counter += 1
#             if self.counter >= self.patience:
#                 return True
#         else:
#             self.best_score = val_score
#             self.counter = 0
#         return False


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 6. å•æŠ˜è®­ç»ƒå‡½æ•° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def train_single_fold(train_dataset: Dataset,
                      val_dataset: Dataset,
                      fold_idx: int,
                      verbose: bool = True) -> Tuple[float, Dict]:
    """
    è®­ç»ƒå•ä¸ªæŠ˜å 

    Args:
        train_dataset: è®­ç»ƒæ•°æ®é›†
        val_dataset: éªŒè¯æ•°æ®é›†
        fold_idx: æŠ˜å ç´¢å¼•
        verbose: æ˜¯å¦æ‰“å°è¯¦ç»†ä¿¡æ¯

    Returns:
        best_c_index: æœ€ä½³C-index
        history: è®­ç»ƒå†å²
    """

    # æ•°æ®åŠ è½½å™¨
    train_loader = DataLoader(train_dataset, batch_size=CONFIG["BATCH_SIZE"],
                              shuffle=True, num_workers=0)
    val_loader = DataLoader(val_dataset, batch_size=1024,
                            shuffle=False, num_workers=0)

    # æ¨¡å‹å’Œä¼˜åŒ–å™¨
    device = torch.device(CONFIG["DEVICE"])
    feat_dim = train_dataset[0][0].shape[0]
    model = DeepSurvMLP(num_features=feat_dim).to(device)
    optim = torch.optim.Adam(model.parameters(),
                             lr=CONFIG["LR"],
                             weight_decay=CONFIG["WEIGHT_DECAY"])

    # æ—©åœ
    # early_stopping = EarlyStopping(patience=CONFIG["PATIENCE"],
    #                                min_delta=CONFIG["MIN_DELTA"])

    # è®­ç»ƒå†å²
    history = {
        'train_loss': [],
        'val_c_index': [],
        'epochs': 0
    }

    best_c = 0.0

    for epoch in range(1, CONFIG["EPOCHS"] + 1):
        # â”€â”€â”€ Train â”€â”€â”€
        model.train()
        train_loss = 0.
        for x, t, e in train_loader:
            x, t, e = (x.to(device), t.to(device), e.to(device))
            risk = model(x)
            loss = cox_ph_loss(risk, t, e)
            optim.zero_grad()
            loss.backward()
            optim.step()
            train_loss += loss.item()
        train_loss /= len(train_loader)

        # â”€â”€â”€ Validate â”€â”€â”€
        model.eval()
        with torch.no_grad():
            risks, times, events = [], [], []
            for x, t, e in val_loader:
                r = model(x.to(device)).cpu()
                risks.append(r)
                times.append(t)
                events.append(e)
            risks = torch.cat(risks).numpy()
            times = torch.cat(times).numpy()
            events = torch.cat(events).numpy()
            c_val = concordance_index(times, -risks, events)

        # è®°å½•å†å²
        history['train_loss'].append(train_loss)
        history['val_c_index'].append(c_val)
        history['epochs'] = epoch

        # ä¿å­˜æœ€ä¼˜
        if c_val > best_c:
            best_c = c_val
            # ä¿å­˜å½“å‰æŠ˜å çš„æœ€ä½³æ¨¡å‹
            torch.save(model.state_dict(), f"best_deepsurv_fold_{fold_idx}.pth")

        if verbose and (epoch % 100 == 0 or epoch <= 10):
            print(f"  Fold {fold_idx} - Epoch [{epoch:03d}/{CONFIG['EPOCHS']}]  "
                  f"train loss {train_loss:6.3f} | val C-index {c_val:5.3f}")

        # æ—©åœæ£€æŸ¥
        # if early_stopping(c_val):
        #     if verbose:
        #         print(f"  Fold {fold_idx} - æ—©åœäºç¬¬ {epoch} è½®")
        #     break

    return best_c, history


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 7. äº¤å‰éªŒè¯ä¸»å‡½æ•° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def train_deepsurv_cv(x_csv: str, y_csv: str, output_dir: str = "./cv_results"):
    """
    5å€äº¤å‰éªŒè¯è®­ç»ƒDeepSurv

    Args:
        x_csv: ç‰¹å¾æ–‡ä»¶è·¯å¾„
        y_csv: æ ‡ç­¾æ–‡ä»¶è·¯å¾„
        output_dir: è¾“å‡ºç›®å½•
    """

    print("=" * 60)
    print("ğŸš€ DeepSurv 5å€äº¤å‰éªŒè¯è®­ç»ƒ")
    print("=" * 60)

    # è®¾ç½®éšæœºç§å­
    torch.manual_seed(CONFIG["SEED"])
    np.random.seed(CONFIG["SEED"])

    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(output_dir, exist_ok=True)

    # åŠ è½½å®Œæ•´æ•°æ®é›†
    full_dataset = SurvivalDataset(x_csv, y_csv)
    n_samples = len(full_dataset)
    feat_dim = full_dataset[0][0].shape[0]

    print(f"ğŸ“Š æ•°æ®ä¿¡æ¯:")
    print(f"  æ ·æœ¬æ•°é‡: {n_samples}")
    print(f"  ç‰¹å¾ç»´åº¦: {feat_dim}")
    print(f"  äº‹ä»¶ç‡: {full_dataset.event.mean():.3f}")
    print(f"  è®¾å¤‡: {CONFIG['DEVICE']}")

    # 5å€äº¤å‰éªŒè¯
    kfold = KFold(n_splits=CONFIG["CV_FOLDS"], shuffle=True, random_state=CONFIG["SEED"])

    # å­˜å‚¨ç»“æœ
    cv_results = {
        'fold_c_indices': [],
        'fold_histories': [],
        'fold_train_sizes': [],
        'fold_val_sizes': []
    }

    print(f"\nğŸ”„ å¼€å§‹ {CONFIG['CV_FOLDS']} å€äº¤å‰éªŒè¯...")

    for fold_idx, (train_indices, val_indices) in enumerate(kfold.split(range(n_samples))):
        print(f"\nğŸ“ è®­ç»ƒç¬¬ {fold_idx + 1} æŠ˜...")
        print(f"  è®­ç»ƒé›†å¤§å°: {len(train_indices)}")
        print(f"  éªŒè¯é›†å¤§å°: {len(val_indices)}")

        # åˆ›å»ºå½“å‰æŠ˜å çš„æ•°æ®é›†
        train_dataset = Subset(full_dataset, train_indices)
        val_dataset = Subset(full_dataset, val_indices)

        # è®­ç»ƒå½“å‰æŠ˜å 
        fold_c_index, fold_history = train_single_fold(
            train_dataset, val_dataset, fold_idx + 1, verbose=True
        )

        # ä¿å­˜ç»“æœ
        cv_results['fold_c_indices'].append(fold_c_index)
        cv_results['fold_histories'].append(fold_history)
        cv_results['fold_train_sizes'].append(len(train_indices))
        cv_results['fold_val_sizes'].append(len(val_indices))

        print(f"  âœ… ç¬¬ {fold_idx + 1} æŠ˜å®Œæˆï¼Œæœ€ä½³ C-index: {fold_c_index:.4f}")

    # è®¡ç®—äº¤å‰éªŒè¯ç»Ÿè®¡
    cv_c_indices = np.array(cv_results['fold_c_indices'])
    mean_c_index = cv_c_indices.mean()
    std_c_index = cv_c_indices.std()

    print(f"\n" + "=" * 60)
    print("ğŸ“ˆ äº¤å‰éªŒè¯ç»“æœæ±‡æ€»")
    print("=" * 60)
    print(f"å„æŠ˜ C-index: {cv_c_indices}")
    print(f"å¹³å‡ C-index: {mean_c_index:.4f} Â± {std_c_index:.4f}")
    print(f"æœ€ä½³ C-index: {cv_c_indices.max():.4f}")
    print(f"æœ€å·® C-index: {cv_c_indices.min():.4f}")

    # ä¿å­˜ç»“æœåˆ°æ–‡ä»¶
    results_df = pd.DataFrame({
        'Fold': range(1, CONFIG['CV_FOLDS'] + 1),
        'C_Index': cv_c_indices,
        'Train_Size': cv_results['fold_train_sizes'],
        'Val_Size': cv_results['fold_val_sizes'],
        'Epochs': [h['epochs'] for h in cv_results['fold_histories']]
    })
    results_df.to_csv(os.path.join(output_dir, 'cv_results.csv'), index=False)

    # ç»˜åˆ¶ç»“æœå›¾è¡¨
    plot_cv_results(cv_results, output_dir, mean_c_index, std_c_index)

    # ä¿å­˜é…ç½®
    config_df = pd.DataFrame([CONFIG]).T
    config_df.columns = ['Value']
    config_df.to_csv(os.path.join(output_dir, 'config.csv'))

    print(f"ğŸ“ ç»“æœå·²ä¿å­˜åˆ°: {output_dir}")

    return {
        'mean_c_index': mean_c_index,
        'std_c_index': std_c_index,
        'fold_c_indices': cv_c_indices,
        'fold_histories': cv_results['fold_histories'],
        'config': CONFIG
    }


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 8. ç»“æœå¯è§†åŒ– â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def plot_cv_results(cv_results: Dict, output_dir: str, mean_c: float, std_c: float):
    """ç»˜åˆ¶äº¤å‰éªŒè¯ç»“æœ"""

    plt.figure(figsize=(20, 12))

    # 1. C-index æŸ±çŠ¶å›¾
    plt.subplot(2, 3, 1)
    fold_indices = range(1, len(cv_results['fold_c_indices']) + 1)
    bars = plt.bar(fold_indices, cv_results['fold_c_indices'],
                   color='skyblue', alpha=0.7, edgecolor='navy')
    plt.axhline(y=mean_c, color='red', linestyle='--',
                label=f'å¹³å‡: {mean_c:.4f}Â±{std_c:.4f}')
    plt.xlabel('æŠ˜å ')
    plt.ylabel('C-index')
    plt.title('å„æŠ˜ C-index å¯¹æ¯”')
    plt.legend()
    plt.grid(True, alpha=0.3)

    # æ·»åŠ æ•°å€¼æ ‡ç­¾
    for bar, c_idx in zip(bars, cv_results['fold_c_indices']):
        plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 0.005,
                 f'{c_idx:.3f}', ha='center', va='bottom', fontsize=10)

    # 2. è®­ç»ƒæ›²çº¿ï¼ˆæ‰€æœ‰æŠ˜å ï¼‰
    plt.subplot(2, 3, 2)
    colors = ['blue', 'red', 'green', 'orange', 'purple']
    for i, history in enumerate(cv_results['fold_histories']):
        plt.plot(history['val_c_index'], color=colors[i % len(colors)],
                 alpha=0.7, label=f'Fold {i + 1}')
    plt.xlabel('Epoch')
    plt.ylabel('éªŒè¯ C-index')
    plt.title('è®­ç»ƒè¿‡ç¨‹ - éªŒè¯ C-index')
    plt.legend()
    plt.grid(True, alpha=0.3)

    # 3. æŸå¤±æ›²çº¿ï¼ˆæ‰€æœ‰æŠ˜å ï¼‰
    plt.subplot(2, 3, 3)
    for i, history in enumerate(cv_results['fold_histories']):
        plt.plot(history['train_loss'], color=colors[i % len(colors)],
                 alpha=0.7, label=f'Fold {i + 1}')
    plt.xlabel('Epoch')
    plt.ylabel('è®­ç»ƒæŸå¤±')
    plt.title('è®­ç»ƒè¿‡ç¨‹ - è®­ç»ƒæŸå¤±')
    plt.legend()
    plt.grid(True, alpha=0.3)

    # 4. C-index åˆ†å¸ƒç®±çº¿å›¾
    plt.subplot(2, 3, 4)
    plt.boxplot(cv_results['fold_c_indices'], patch_artist=True,
                boxprops=dict(facecolor='lightblue', alpha=0.7))
    plt.ylabel('C-index')
    plt.title('C-index åˆ†å¸ƒ')
    plt.grid(True, alpha=0.3)

    # 5. è®­ç»ƒé›†/éªŒè¯é›†å¤§å°
    plt.subplot(2, 3, 5)
    x = np.arange(len(fold_indices))
    width = 0.35
    plt.bar(x - width / 2, cv_results['fold_train_sizes'], width,
            label='è®­ç»ƒé›†', alpha=0.7, color='lightcoral')
    plt.bar(x + width / 2, cv_results['fold_val_sizes'], width,
            label='éªŒè¯é›†', alpha=0.7, color='lightblue')
    plt.xlabel('æŠ˜å ')
    plt.ylabel('æ ·æœ¬æ•°é‡')
    plt.title('å„æŠ˜æ•°æ®é›†å¤§å°')
    plt.xticks(x, fold_indices)
    plt.legend()
    plt.grid(True, alpha=0.3)

    # 6. ç»Ÿè®¡æ‘˜è¦
    plt.subplot(2, 3, 6)
    stats_text = [
        f"DeepSurv 5å€äº¤å‰éªŒè¯ç»“æœ",
        f"",
        f"å¹³å‡ C-index: {mean_c:.4f}",
        f"æ ‡å‡†å·®: {std_c:.4f}",
        f"æœ€ä½³: {max(cv_results['fold_c_indices']):.4f}",
        f"æœ€å·®: {min(cv_results['fold_c_indices']):.4f}",
        f"",
        f"æ¨¡å‹é…ç½®:",
        f"éšè—å±‚: {CONFIG['HIDDEN_SIZES']}",
        f"Dropout: {CONFIG['DROPOUT']}",
        f"å­¦ä¹ ç‡: {CONFIG['LR']}",
        f"æ‰¹æ¬¡å¤§å°: {CONFIG['BATCH_SIZE']}",
        f"æœ€å¤§è½®æ•°: {CONFIG['EPOCHS']}",
        f"",
        f"æ€§èƒ½è¯„ä¼°:",
        f"{'ä¼˜ç§€' if mean_c > 0.75 else 'è‰¯å¥½' if mean_c > 0.65 else 'ä¸€èˆ¬'} "
        f"(C-index {mean_c:.3f})",
        f"ç¨³å®šæ€§: {'é«˜' if std_c < 0.05 else 'ä¸­' if std_c < 0.1 else 'ä½'} "
        f"(std {std_c:.3f})"
    ]

    plt.text(0.05, 0.95, '\n'.join(stats_text), fontsize=10,
             verticalalignment='top', transform=plt.gca().transAxes,
             bbox=dict(boxstyle="round,pad=0.3", facecolor="lightgray", alpha=0.8))
    plt.axis('off')
    plt.title('ç»Ÿè®¡æ‘˜è¦')

    plt.tight_layout()
    plt.savefig(os.path.join(output_dir, 'cv_results_analysis.png'),
                dpi=300, bbox_inches='tight')
    plt.close()

    print(f"ğŸ“Š ç»“æœå›¾è¡¨å·²ä¿å­˜: {os.path.join(output_dir, 'cv_results_analysis.png')}")


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 9. åŸå§‹è®­ç»ƒå‡½æ•°ï¼ˆä¿æŒå…¼å®¹æ€§ï¼‰ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def train_deepsurv(x_csv: str, y_csv: str):
    """åŸå§‹è®­ç»ƒå‡½æ•°ï¼ˆæ— äº¤å‰éªŒè¯ï¼‰"""
    torch.manual_seed(CONFIG["SEED"])

    # æ•°æ®å‡†å¤‡
    full_ds = SurvivalDataset(x_csv, y_csv)
    feat_dim = full_ds.x.shape[1]
    n_train = int(CONFIG["TRAIN_RATIO"] * len(full_ds))
    train_ds, val_ds = torch.utils.data.random_split(
        full_ds,
        [n_train, len(full_ds) - n_train],
        generator=torch.Generator().manual_seed(CONFIG["SEED"])
    )

    train_loader = DataLoader(train_ds, batch_size=CONFIG["BATCH_SIZE"],
                              shuffle=True, num_workers=0)
    val_loader = DataLoader(val_ds, batch_size=1024,
                            shuffle=False, num_workers=0)

    # å»ºç«‹æ¨¡å‹ä¸ä¼˜åŒ–å™¨
    device = torch.device(CONFIG["DEVICE"])
    model = DeepSurvMLP(num_features=feat_dim).to(device)
    optim = torch.optim.Adam(model.parameters(),
                             lr=CONFIG["LR"],
                             weight_decay=CONFIG["WEIGHT_DECAY"])

    best_c = 0.0
    for epoch in range(1, CONFIG["EPOCHS"] + 1):
        # â”€â”€â”€ Train â”€â”€â”€
        model.train()
        train_loss = 0.
        for x, t, e in train_loader:
            x, t, e = (x.to(device), t.to(device), e.to(device))
            risk = model(x)
            loss = cox_ph_loss(risk, t, e)
            optim.zero_grad();
            loss.backward();
            optim.step()
            train_loss += loss.item()
        train_loss /= len(train_loader)

        # â”€â”€â”€ Validate â”€â”€â”€
        model.eval()
        with torch.no_grad():
            risks, times, events = [], [], []
            for x, t, e in val_loader:
                r = model(x.to(device)).cpu()
                risks.append(r);
                times.append(t);
                events.append(e)
            risks = torch.cat(risks).numpy()
            times = torch.cat(times).numpy()
            events = torch.cat(events).numpy()
            c_val = concordance_index(times, -risks, events)

        # ä¿å­˜æœ€ä¼˜
        if c_val > best_c:
            best_c = c_val
            torch.save(model.state_dict(), "best_deepsurv.pth")

        print(f"[{epoch:02d}/{CONFIG['EPOCHS']}]  "
              f"train loss {train_loss:6.3f} | val C-index {c_val:5.3f}")

    print("âœ… Training done.  Best validation C-index =", best_c)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 10. å…¥å£ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if __name__ == "__main__":
    # æ–‡ä»¶è·¯å¾„
    x_csv = "/Users/ouyouyou/Desktop/residual_PA/yanshao/new_fusion/MRI_features.csv"
    y_csv = "/Users/ouyouyou/Desktop/residual_PA/yanshao/new_fusion/PFS_survival.csv"

    print("é€‰æ‹©è®­ç»ƒæ¨¡å¼:")
    print("1. 5å€äº¤å‰éªŒè¯è®­ç»ƒ (æ¨è)")
    print("2. ä¼ ç»Ÿå•æ¬¡è®­ç»ƒ")

    choice = input("è¯·è¾“å…¥é€‰æ‹© (1 æˆ– 2): ").strip()

    if choice == "1":
        # 5å€äº¤å‰éªŒè¯è®­ç»ƒ
        results = train_deepsurv_cv(x_csv, y_csv, output_dir="./deepsurv_cv_results")
        print(f"\nğŸ‰ äº¤å‰éªŒè¯å®Œæˆï¼")
        print(f"å¹³å‡ C-index: {results['mean_c_index']:.4f} Â± {results['std_c_index']:.4f}")
    elif choice == "2":
        # ä¼ ç»Ÿè®­ç»ƒ
        train_deepsurv(x_csv, y_csv)
    else:
        print("æ— æ•ˆé€‰æ‹©ï¼Œé»˜è®¤ä½¿ç”¨äº¤å‰éªŒè¯è®­ç»ƒ")
        results = train_deepsurv_cv(x_csv, y_csv, output_dir="./deepsurv_cv_results")
        print(f"\nğŸ‰ äº¤å‰éªŒè¯å®Œæˆï¼")
        print(f"å¹³å‡ C-index: {results['mean_c_index']:.4f} Â± {results['std_c_index']:.4f}")